
Engineering Manager, Google Core


Content Safety Platform provides safety solutions that protect Google’s users from exposure to offensive, sensitive and / or potentially harmful content.



Not only do we keep users safe at scale, but we also unblock and accelerate Google's innovative product launches by providing high-quality, low-cost implementations of company-wide standards for Responsible AI, making them available off-the-shelf for any product or feature team to use.



Our team combines unique subject matter expertise in the safety domain along with our production-grade experience in serving infrastructure and product integrations to protect users from harm, maintain Google’s competitiveness in the area of online safety across the industry, and do our part to make the internet as a whole safer for society as a whole



You will be part of a global team of engineers building content safety solutions to safeguard business-critical products that represent significant revenue, market share and / or strategic value to Google, including GenAI-based experiences both server-side and on-device.



You bring a mix of high-scale distributed systems engineering skills and machine learning experience to design, build, maintain and scale content safety solutions that include rules, blocklists, heuristics, vector databases, scalable classifiers and large models. These services are used by products across Google to make the user experience safer.



Main responsibilities:



Lead, hire, mentor, grow, and empower a team of engineers focused on Responsible AI within Content Safety Applications.
Drive the development of infrastructure and tools to build and improve content safety classifiers and responsible AI systems for Google products, including Generative AI experiences.
Collaborate closely with engineering partners, product managers, and policy stakeholders to drive alignment on technical strategy and execution for AI and content safety initiatives.
Ensure the delivery of high-quality, future-proof, and performing AI and content safety solutions that protect users and unlock new business opportunities.
Contribute to the strategic direction of the team, identifying opportunities for innovation and improvement in the AI and content safety landscape.

--- 
PREP



1. Interview readiness programs:

Feel free to explore Google Pathways, it's an interview readiness initiative designed to empower you to excel in interviewing at Google. We focus on comprehensive interview preparation: live training sessions to sign up, additional prep materials, and access to new tools. There are some helpful sessions scheduled for the next few days, if you'd like to explore them, but you can also sign up for Educative subscriptions (system design). 

2. Interview structure: the first round

1 systems architecture interviews (60 mins) - you will receive a link to schedule the round shortly. I'd advise to input closest availability as I've mentioned we have quite a strict deadline.


3. Preparation materials:

You will find all the details about how to prepare for the interviews here, including: what is important during systems architecture interviews, potential questions and additional resources. 

I would advise you to use GenAI to prepare/practice for this interview,
Please do not use AI during the interview. Using AI during the interview will result in disqualification from the hiring process. 
 
4. What happens after the interviews?

Breathe and relax! As soon as I receive the feedback, I'll share it with you and we'll discuss the next steps. Usually the feedback is provided within a few days. 



Best of luck! In case of any questions, please let me know! 


Kind regards,


